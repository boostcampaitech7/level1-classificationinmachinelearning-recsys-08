{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>16536.747967</td>\n",
       "      <td>5516.420322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>16557.136536</td>\n",
       "      <td>4513.341881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>16548.149805</td>\n",
       "      <td>4310.904314</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>16533.632875</td>\n",
       "      <td>4893.417864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>16524.712159</td>\n",
       "      <td>5209.002297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime         close       volume  weekend\n",
       "0 2023-01-01 00:00:00  16536.747967  5516.420322        1\n",
       "1 2023-01-01 01:00:00  16557.136536  4513.341881        1\n",
       "2 2023-01-01 02:00:00  16548.149805  4310.904314        1\n",
       "3 2023-01-01 03:00:00  16533.632875  4893.417864        1\n",
       "4 2023-01-01 04:00:00  16524.712159  5209.002297        1"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일 호출\n",
    "data_path = os.getcwd() + '\\\\data\\\\data\\\\'\n",
    "df = pd.read_csv(data_path + 'HOURLY_MARKET-DATA_PRICE-OHLCV_ALL_EXCHANGE_SPOT_BTC_USD.csv')\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['weekend'] = (df['datetime'].dt.dayofweek >= 5).astype(int)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "cutoff = \"2023-04-01\"\n",
    "train_df = df[df['datetime']>=cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.DataFrame({\"ds\": train_df[\"datetime\"], \"y\": train_df[\"close\"], \"weekend\": train_df[\"weekend\"]})\n",
    "\n",
    "train = train.dropna()\n",
    "train = train.replace([np.inf, -np.inf], np.nan).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralprophet import NeuralProphet, set_log_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.985% of the data.\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\data\\process.py:496: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_grouped = df.groupby(\"ID\").apply(lambda x: x.set_index(\"ds\").resample(freq).asfreq()).drop(columns=[\"ID\"])\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: |          | 0/? [02:09<?, ?it/s, v_num=4, train_loss=0.000784, reg_loss=2.93e-5, MAE=299.0, RMSE=437.0, Loss=0.000782, RegLoss=2.93e-5]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>reg_loss</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Loss</th>\n",
       "      <th>RegLoss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.148282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4735.522461</td>\n",
       "      <td>8172.810059</td>\n",
       "      <td>0.147439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>588.464417</td>\n",
       "      <td>800.017212</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>478.902496</td>\n",
       "      <td>672.974731</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>469.352844</td>\n",
       "      <td>659.555237</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>463.427063</td>\n",
       "      <td>650.180420</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>298.663269</td>\n",
       "      <td>436.709686</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>298.665741</td>\n",
       "      <td>437.402985</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>299.625946</td>\n",
       "      <td>438.079407</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>298.459412</td>\n",
       "      <td>437.164001</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>299.405273</td>\n",
       "      <td>437.241211</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  reg_loss          MAE         RMSE      Loss   RegLoss  epoch\n",
       "0     0.148282  0.000000  4735.522461  8172.810059  0.147439  0.000000      0\n",
       "1     0.002681  0.000000   588.464417   800.017212  0.002672  0.000000      1\n",
       "2     0.001829  0.000000   478.902496   672.974731  0.001828  0.000000      2\n",
       "3     0.001750  0.000000   469.352844   659.555237  0.001748  0.000000      3\n",
       "4     0.001690  0.000000   463.427063   650.180420  0.001694  0.000000      4\n",
       "..         ...       ...          ...          ...       ...       ...    ...\n",
       "95    0.000785  0.000030   298.663269   436.709686  0.000783  0.000030     95\n",
       "96    0.000785  0.000030   298.665741   437.402985  0.000785  0.000030     96\n",
       "97    0.000784  0.000029   299.625946   438.079407  0.000784  0.000029     97\n",
       "98    0.000785  0.000030   298.459412   437.164001  0.000783  0.000030     98\n",
       "99    0.000784  0.000029   299.405273   437.241211  0.000782  0.000029     99\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 정의\n",
    "m2 = NeuralProphet(\n",
    "    growth=\"linear\",\n",
    "    n_changepoints=10,\n",
    "    changepoints_range=0.9,\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    seasonality_mode=\"multiplicative\",\n",
    "    n_lags=24,\n",
    "    ar_reg=0.1,\n",
    "    n_forecasts=24,\n",
    "    learning_rate=0.05,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    loss_func=\"Huber\"\n",
    ")\n",
    "\n",
    "# 추가 계절성 정의\n",
    "m2 = m2.add_seasonality(name=\"quarterly\", period=90, fourier_order=5)\n",
    "m2 = m2.add_seasonality(name=\"monthly\", period=30, fourier_order=3)\n",
    "\n",
    "# 주말 효과 추가\n",
    "m2 = m2.add_events([\"weekend\"])\n",
    "m2.fit(train, freq=\"H\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\findu\\AppData\\Local\\Temp\\ipykernel_26416\\3126001539.py:15: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  extra_dates = pd.date_range(start=last_future_date + pd.Timedelta(hours=1), periods=24, freq='H')\n"
     ]
    }
   ],
   "source": [
    "# 1. future 데이터프레임 읽기\n",
    "future = pd.read_csv(data_path + 'test.csv')\n",
    "future['ds'] = pd.to_datetime(future['ID'])\n",
    "future = future.drop(columns='ID', axis=1)\n",
    "future['y'] = 0\n",
    "future['weekend'] = (future['ds'].dt.dayofweek >= 5).astype(int)\n",
    "\n",
    "# 2. train 데이터의 마지막 24시간 데이터 가져오기\n",
    "last_day_train = train[train['ds'] >= '2023-12-31']\n",
    "\n",
    "last_day_train.tail()\n",
    "\n",
    "# 3. future 데이터의 마지막 날짜 이후 24시간 생성\n",
    "last_future_date = future['ds'].max()\n",
    "extra_dates = pd.date_range(start=last_future_date + pd.Timedelta(hours=1), periods=24, freq='H')\n",
    "extra_future = pd.DataFrame({'ds': extra_dates})\n",
    "extra_future['y'] = 0\n",
    "extra_future['weekend'] = (extra_future['ds'].dt.dayofweek >= 5).astype(int)\n",
    "\n",
    "extra_future.tail()\n",
    "\n",
    "# 4. 데이터 합치기\n",
    "combined_future = pd.concat([last_day_train, future, extra_future], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.965% of the data.\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.965% of the data.\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\data\\process.py:496: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_grouped = df.groupby(\"ID\").apply(lambda x: x.set_index(\"ds\").resample(freq).asfreq()).drop(columns=[\"ID\"])\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 54.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last prediction date: 2024-04-26 07:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\findu\\AppData\\Local\\Temp\\ipykernel_26416\\3854612461.py:8: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  predict['price_change'] = predict['predicted_price'].pct_change().fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# 5. 예측 수행\n",
    "forecast = m2.predict(combined_future)\n",
    "\n",
    "# 6. 예측 결과 처리\n",
    "predict = forecast[['ds', 'yhat1']].rename(columns={'yhat1': 'predicted_price'})\n",
    "\n",
    "# 7. 가격 변화율 계산 (NaN 값 처리)\n",
    "predict['price_change'] = predict['predicted_price'].pct_change().fillna(0)\n",
    "\n",
    "# 8. 가격 등락을 0~3으로 나타내는 함수 정의\n",
    "def classify_price_change(change):\n",
    "    if np.isnan(change):\n",
    "        return None\n",
    "    elif change < -0.005:\n",
    "        return 0\n",
    "    elif -0.005 <= change < 0:\n",
    "        return 1\n",
    "    elif 0 <= change < 0.005:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# 9. 가격 등락 분류 적용\n",
    "predict['price_change_category'] = predict['price_change'].apply(classify_price_change)\n",
    "\n",
    "# 10. 결과 필터링 (원래 future 데이터의 범위만 선택)\n",
    "predict_filtered = predict[(predict['ds'] >= future['ds'].min()) & (predict['ds'] <= future['ds'].max())]\n",
    "\n",
    "# 11. 결과 확인\n",
    "#print(predict_filtered[['ds', 'predicted_price', 'price_change', 'price_change_category']])\n",
    "\n",
    "# 12. CSV 파일로 저장\n",
    "#predict_filtered.to_csv('bitcoin_price_prediction_with_categories.csv', index=False)\n",
    "\n",
    "csv = predict_filtered[['ds', 'price_change_category']].rename(columns={'ds': 'ID', 'price_change_category' : 'target'})\n",
    "csv.to_csv('output.csv', index=False)\n",
    "\n",
    "# 13. 마지막 예측 날짜 확인\n",
    "print(\"Last prediction date:\", predict_filtered['ds'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ds    y  weekend\n",
       "0 2024-01-01 00:00:00  0.0        0\n",
       "1 2024-01-01 01:00:00  0.0        0\n",
       "2 2024-01-01 02:00:00  0.0        0\n",
       "3 2024-01-01 03:00:00  0.0        0\n",
       "4 2024-01-01 04:00:00  0.0        0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. future 데이터프레임 읽기\n",
    "future = pd.read_csv(data_path + 'test.csv')\n",
    "future['ds'] = pd.to_datetime(future['ID'])\n",
    "future = future.drop(columns='ID', axis=1)\n",
    "future['y'] = 0\n",
    "future['weekend'] = (future['ds'].dt.dayofweek >= 5).astype(int)\n",
    "future.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.964% of the data.\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.964% of the data.\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1173: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  aux_ts = pd.DataFrame(pd.date_range(\"1994-01-01\", periods=100, freq=freq_str))\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - H\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\data\\process.py:496: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_grouped = df.groupby(\"ID\").apply(lambda x: x.set_index(\"ds\").resample(freq).asfreq()).drop(columns=[\"ID\"])\n",
      "c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 48.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                      ds  predicted_price  price_change  price_change_category\n",
      "0    2024-01-01 00:00:00              NaN           0.0                      2\n",
      "1    2024-01-01 01:00:00              NaN           0.0                      2\n",
      "2    2024-01-01 02:00:00              NaN           0.0                      2\n",
      "3    2024-01-01 03:00:00              NaN           0.0                      2\n",
      "4    2024-01-01 04:00:00              NaN           0.0                      2\n",
      "...                  ...              ...           ...                    ...\n",
      "2787 2024-04-26 03:00:00              NaN           0.0                      2\n",
      "2788 2024-04-26 04:00:00              NaN           0.0                      2\n",
      "2789 2024-04-26 05:00:00              NaN           0.0                      2\n",
      "2790 2024-04-26 06:00:00              NaN           0.0                      2\n",
      "2791 2024-04-26 07:00:00              NaN           0.0                      2\n",
      "\n",
      "[2792 rows x 4 columns]\n",
      "Last prediction date: 2024-04-26 07:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\findu\\AppData\\Local\\Temp\\ipykernel_26416\\2655030634.py:8: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  predict['price_change'] = predict['predicted_price'].pct_change().fillna(0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. 예측 수행\n",
    "forecast = m2.predict(df=future)\n",
    "\n",
    "# 3. 예측 결과 처리\n",
    "predict = forecast[['ds', 'yhat1']].rename(columns={'yhat1': 'predicted_price'})\n",
    "\n",
    "# 4. 가격 변화율 계산 (NaN 값 처리)\n",
    "predict['price_change'] = predict['predicted_price'].pct_change().fillna(0)\n",
    "\n",
    "# 5. 가격 등락을 0~3으로 나타내는 함수 정의\n",
    "def classify_price_change(change):\n",
    "    if np.isnan(change):\n",
    "        return None\n",
    "    elif change < -0.005:\n",
    "        return 0\n",
    "    elif -0.005 <= change < 0:\n",
    "        return 1\n",
    "    elif 0 <= change < 0.005:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# 6. 가격 등락 분류 적용\n",
    "predict['price_change_category'] = predict['price_change'].apply(classify_price_change)\n",
    "\n",
    "# 7. 결과 필터링 (2024-01-01 00:00:00부터 2024-04-26 07:00:00까지)\n",
    "start_date = pd.to_datetime('2024-01-01 00:00:00')\n",
    "end_date = pd.to_datetime('2024-04-26 07:00:00')\n",
    "predict_filtered = predict[(predict['ds'] >= start_date) & (predict['ds'] <= end_date)]\n",
    "\n",
    "# 8. 결과 확인\n",
    "print(predict_filtered[['ds', 'predicted_price', 'price_change', 'price_change_category']])\n",
    "\n",
    "# 9. CSV 파일로 저장\n",
    "predict_filtered.to_csv('bitcoin_price_prediction_with_categories.csv', index=False)\n",
    "\n",
    "# 10. 마지막 예측 날짜 확인\n",
    "print(\"Last prediction date:\", predict['ds'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 11. 추가: 트렌드 컴포넌트 확인 (선택사항)\n",
    "if 'trend' in forecast.columns:\n",
    "    print(\"\\nTrend component:\")\n",
    "    print(forecast[['ds', 'trend']].head())\n",
    "\n",
    "# 12. 추가: 다른 예측 기간에 대한 결과 확인 (선택사항)\n",
    "if 'yhat2' in forecast.columns:\n",
    "    print(\"\\n2-step ahead prediction:\")\n",
    "    print(forecast[['ds', 'yhat2']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output File Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file 할당후 save \n",
    "submission_df = submission_df.assign(target = y_test_pred_class)\n",
    "submission_df.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neuralprophet import NeuralProphet\n",
    "import os\n",
    "\n",
    "data_path = os.getcwd() + '\\\\data\\\\data\\\\'\n",
    "# 1. 데이터 로드 및 전처리\n",
    "train = pd.read_csv(data_path + 'HOURLY_MARKET-DATA_PRICE-OHLCV_ALL_EXCHANGE_SPOT_BTC_USD.csv')\n",
    "train.head()\n",
    "train['datetime'] = pd.to_datetime(train['datetime'])\n",
    "train = train.rename(columns={'close': 'y', 'datetime' : 'ds'})\n",
    "train = train.drop(columns='volume', axis=1)\n",
    "cutoff = \"2023-04-01\"\n",
    "train = train[train['ds']>=cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>2023-04-01 00:00:00</td>\n",
       "      <td>28441.265996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>2023-04-01 01:00:00</td>\n",
       "      <td>28614.022826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>2023-04-01 02:00:00</td>\n",
       "      <td>28576.108274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>2023-04-01 03:00:00</td>\n",
       "      <td>28534.295250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>2023-04-01 04:00:00</td>\n",
       "      <td>28579.253756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ds             y\n",
       "2160 2023-04-01 00:00:00  28441.265996\n",
       "2161 2023-04-01 01:00:00  28614.022826\n",
       "2162 2023-04-01 02:00:00  28576.108274\n",
       "2163 2023-04-01 03:00:00  28534.295250\n",
       "2164 2023-04-01 04:00:00  28579.253756"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = pd.read_csv(data_path + 'test.csv')\n",
    "future['ds'] = pd.to_datetime(future['ID'])\n",
    "future = future.drop(columns='ID', axis=1)\n",
    "future['y'] = np.nan  # 예측할 값은 NaN으로 설정\n",
    "\n",
    "# 2. 데이터 스케일링\n",
    "scale_factor = 1000  # 가격을 1000으로 나눔\n",
    "train['y'] = train['y'] / scale_factor\n",
    "future['y'] = future['y'] / scale_factor\n",
    "\n",
    "# 3. 주말 정보 추가\n",
    "train['weekend'] = (train['ds'].dt.dayofweek >= 5).astype(int)\n",
    "future['weekend'] = (future['ds'].dt.dayofweek >= 5).astype(int)\n",
    "\n",
    "# 4. train 데이터의 마지막 24시간 데이터 가져오기\n",
    "last_day_train = train[train['ds'] >= train['ds'].max() - pd.Timedelta(days=1)]\n",
    "\n",
    "# 5. future 데이터의 마지막 날짜 이후 24시간 생성\n",
    "last_future_date = future['ds'].max()\n",
    "extra_dates = pd.date_range(start=last_future_date + pd.Timedelta(hours=1), periods=24, freq='h')\n",
    "extra_future = pd.DataFrame({'ds': extra_dates, 'y': np.nan, 'weekend': (extra_dates.dayofweek >= 5).astype(int)})\n",
    "\n",
    "# 6. 데이터 합치기\n",
    "combined_future = pd.concat([last_day_train, future, extra_future], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.985% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - h\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 1/100 [00:00<00:00, 991.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 48. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: |          | 0/? [01:25<?, ?it/s, v_num=5, train_loss=0.000347, reg_loss=0.000149, MAE=0.000143, RMSE=0.000227, Loss=0.000347, RegLoss=0.000149]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>reg_loss</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Loss</th>\n",
       "      <th>RegLoss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.356511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>0.014665</td>\n",
       "      <td>0.355856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.078668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004035</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.078610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.033370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.033340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.016218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.008090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  reg_loss       MAE      RMSE      Loss   RegLoss  epoch\n",
       "0     0.356511  0.000000  0.011657  0.014665  0.355856  0.000000      0\n",
       "1     0.078668  0.000000  0.004035  0.004926  0.078610  0.000000      1\n",
       "2     0.033370  0.000000  0.002526  0.003072  0.033340  0.000000      2\n",
       "3     0.016234  0.000000  0.001737  0.002128  0.016218  0.000000      3\n",
       "4     0.008097  0.000000  0.001215  0.001500  0.008090  0.000000      4\n",
       "..         ...       ...       ...       ...       ...       ...    ...\n",
       "95    0.000348  0.000149  0.000144  0.000226  0.000348  0.000149     95\n",
       "96    0.000348  0.000149  0.000143  0.000226  0.000348  0.000149     96\n",
       "97    0.000348  0.000149  0.000144  0.000227  0.000348  0.000149     97\n",
       "98    0.000348  0.000149  0.000144  0.000226  0.000348  0.000149     98\n",
       "99    0.000347  0.000149  0.000143  0.000227  0.000347  0.000149     99\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 7. 모델 재정의 및 학습\n",
    "m = NeuralProphet(\n",
    "    growth=\"linear\",\n",
    "    n_changepoints=10,\n",
    "    changepoints_range=0.9,\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    seasonality_mode=\"multiplicative\",\n",
    "    n_lags=24,\n",
    "    n_forecasts=1,\n",
    "    ar_reg=0.1,\n",
    "    learning_rate=0.01,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    loss_func=\"Huber\"\n",
    ")\n",
    "\n",
    "# 추가 계절성 정의\n",
    "m = m.add_seasonality(name=\"quarterly\", period=90, fourier_order=5)\n",
    "m = m.add_seasonality(name=\"monthly\", period=30, fourier_order=3)\n",
    "\n",
    "# 주말 효과 추가\n",
    "m = m.add_events([\"weekend\"])\n",
    "m.fit(train, freq=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\findu\\AppData\\Local\\Temp\\ipykernel_32968\\3049193472.py:15: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  extra_dates = pd.date_range(start=last_future_date + pd.Timedelta(hours=1), periods=24, freq='H')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.965% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - h\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency h corresponds to 99.965% of the data.\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - c:\\Users\\findu\\Desktop\\중요하고 급한 폴더\\tothemars\\.conda\\lib\\site-packages\\neuralprophet\\df_utils.py:1152: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  converted_ds = pd.to_datetime(ds_col, utc=True).view(dtype=np.int64)\n",
      "\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - h\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 89.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last prediction date: 2024-04-26 07:00:00\n"
     ]
    }
   ],
   "source": [
    "# 1. future 데이터프레임 읽기\n",
    "future = pd.read_csv(data_path + 'test.csv')\n",
    "future['ds'] = pd.to_datetime(future['ID'])\n",
    "future = future.drop(columns='ID', axis=1)\n",
    "future['y'] = 0\n",
    "future['weekend'] = (future['ds'].dt.dayofweek >= 5).astype(int)\n",
    "\n",
    "# 2. train 데이터의 마지막 24시간 데이터 가져오기\n",
    "last_day_train = train[train['ds'] >= '2023-12-31']\n",
    "\n",
    "last_day_train.tail()\n",
    "\n",
    "# 3. future 데이터의 마지막 날짜 이후 24시간 생성\n",
    "last_future_date = future['ds'].max()\n",
    "extra_dates = pd.date_range(start=last_future_date + pd.Timedelta(hours=1), periods=24, freq='H')\n",
    "extra_future = pd.DataFrame({'ds': extra_dates})\n",
    "extra_future['y'] = 0\n",
    "extra_future['weekend'] = (extra_future['ds'].dt.dayofweek >= 5).astype(int)\n",
    "\n",
    "extra_future.tail()\n",
    "\n",
    "# 4. 데이터 합치기\n",
    "combined_future = pd.concat([last_day_train, future, extra_future], ignore_index=True)\n",
    "\n",
    "# 5. 예측 수행\n",
    "forecast = m.predict(combined_future)\n",
    "\n",
    "# 6. 예측 결과 처리\n",
    "predict = forecast[['ds', 'yhat1']].rename(columns={'yhat1': 'predicted_price'})\n",
    "\n",
    "# 7. 가격 변화율 계산 (NaN 값 처리)\n",
    "predict['price_change'] = predict['predicted_price'].pct_change().fillna(0)\n",
    "\n",
    "# 8. 가격 등락을 0~3으로 나타내는 함수 정의\n",
    "def classify_price_change(change):\n",
    "    if np.isnan(change):\n",
    "        return None\n",
    "    elif change < -0.005:\n",
    "        return 0\n",
    "    elif -0.005 <= change < 0:\n",
    "        return 1\n",
    "    elif 0 <= change < 0.005:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# 9. 가격 등락 분류 적용\n",
    "predict['price_change_category'] = predict['price_change'].apply(classify_price_change)\n",
    "\n",
    "# 10. 결과 필터링 (원래 future 데이터의 범위만 선택)\n",
    "predict_filtered = predict[(predict['ds'] >= future['ds'].min()) & (predict['ds'] <= future['ds'].max())]\n",
    "\n",
    "# 11. 결과 확인\n",
    "#print(predict_filtered[['ds', 'predicted_price', 'price_change', 'price_change_category']])\n",
    "\n",
    "# 12. CSV 파일로 저장\n",
    "predict_filtered.to_csv('bitcoin_price_prediction_with_categories.csv', index=False)\n",
    "\n",
    "csv = predict_filtered[['ds', 'price_change_category']].rename(columns={'ds': 'ID', 'price_change_category' : 'target'})\n",
    "csv.to_csv('output.csv', index=False)\n",
    "\n",
    "# 13. 마지막 예측 날짜 확인\n",
    "print(\"Last prediction date:\", predict_filtered['ds'].max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
