{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU0aC4V7zNlE"
      },
      "source": [
        "### Library Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToJs475PzNlH",
        "outputId": "c1ecec22-6eba-4ae1-a2e4-6507c687411e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import List, Dict\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import lightgbm as lgb\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWmTxdCDzNlI"
      },
      "source": [
        "### Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "d2gssLmd1Wka"
      },
      "outputs": [],
      "source": [
        "data_path: str = \"../../../data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aO_KIBCHzNlI"
      },
      "outputs": [],
      "source": [
        "train_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"train.csv\")).assign(_type=\"train\")\n",
        "test_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")).assign(_type=\"test\")\n",
        "submission_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\"))\n",
        "df: pd.DataFrame = pd.concat([train_df, test_df], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaydZzyPzNlJ",
        "outputId": "cddc0cee-a532-4d04-c2e5-d7508d123aab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 43/43 [00:02<00:00, 18.44it/s]\n"
          ]
        }
      ],
      "source": [
        "# HOURLY_ 로 시작하는 .csv 파일 이름을 file_names 에 할당\n",
        "file_names: List[str] = [\n",
        "    f for f in os.listdir(data_path) if f.startswith(\"HOURLY_\") and 'ALL' in f and f.endswith(\".csv\")\n",
        "]\n",
        "file_names.append('HOURLY_MARKET-DATA_COINBASE-PREMIUM-INDEX.csv')\n",
        "\n",
        "# 'NETWORK'가 포함된 파일 추가\n",
        "network_files = [\n",
        "    f for f in os.listdir(data_path) if 'NETWORK' in f and f.endswith(\".csv\")\n",
        "]\n",
        "\n",
        "# 'NETWORK' 파일들을 기존 file_names 리스트에 추가\n",
        "file_names.extend(network_files)\n",
        "\n",
        "# 파일명 : 데이터프레임으로 딕셔너리 형태로 저장\n",
        "file_dict: Dict[str, pd.DataFrame] = {\n",
        "    f.replace(\".csv\", \"\"): pd.read_csv(os.path.join(data_path, f)) for f in file_names\n",
        "}\n",
        "\n",
        "# 날짜 필터 기준\n",
        "filter_date = \"2023-12-31 23:00:00\"\n",
        "\n",
        "for _file_name, _df in tqdm(file_dict.items()):\n",
        "    # ID (datetime) 열을 기준으로 2023년까지의 데이터만 필터링\n",
        "    _df['datetime'] = pd.to_datetime(_df['datetime'])  # datetime열을 datetime 형식으로 변환\n",
        "    _df = _df[_df['datetime'] <= filter_date]    # 2023년까지만 포함\n",
        "\n",
        "    # 열 이름 중복 방지를 위해 {_file_name.lower()}_{col.lower()}로 변경, datetime 열을 ID로 변경\n",
        "    _rename_rule = {\n",
        "        col: f\"{_file_name.lower()}_{col.lower()}\" if col != \"datetime\" else \"ID\"\n",
        "        for col in _df.columns\n",
        "    }\n",
        "    _df = _df.rename(_rename_rule, axis=1)\n",
        "    df['ID'] = pd.to_datetime(df['ID'])\n",
        "    df = df.merge(_df, on=\"ID\", how=\"left\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzBPI7KizNlK"
      },
      "source": [
        "### EDA (Explanatory Data Analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HtX1d1JYvbPn"
      },
      "outputs": [],
      "source": [
        "# _type에 따라 train, test 분리\n",
        "train_df = df.loc[df[\"_type\"]==\"train\"].drop(columns=[\"_type\"])\n",
        "test_df = df.loc[df[\"_type\"]==\"test\"].drop(columns=[\"_type\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4TxO1zUiiH1g"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
        "\n",
        "def preprocess_data(df, outlier_threshold=5.0):\n",
        "    # 결측치 처리\n",
        "    df = df.dropna(axis=1, how='all')\n",
        "    df_drop = df.drop(columns=['target', '_type'])\n",
        "    df_drop = df_drop.fillna(df_drop.mean())\n",
        "    df.update(df_drop)\n",
        "\n",
        "    # ID, target, _type 열을 제외한 나머지 열로 새로운 데이터프레임 생성\n",
        "    df_drop = df.drop([\"ID\", 'target', \"_type\"], axis=1)\n",
        "\n",
        "    # 이상치 제거\n",
        "    for col in df_drop.columns:\n",
        "        Q1 = df_drop[col].quantile(0.25)\n",
        "        Q3 = df_drop[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        outliers = ((df_drop[col] < lower_bound) | (df_drop[col] > upper_bound)).sum()\n",
        "        outlier_percentage = (outliers / len(df_drop)) * 100\n",
        "\n",
        "        if outlier_percentage > outlier_threshold:\n",
        "            df_drop = df_drop[~((df_drop[col] < lower_bound) | (df_drop[col] > upper_bound))]\n",
        "\n",
        "    # Yeo-Johnson 변환\n",
        "    pt = PowerTransformer(method='yeo-johnson')\n",
        "    for col in df_drop.columns:\n",
        "        df_drop[col] = pt.fit_transform(df_drop[[col]])\n",
        "\n",
        "    # 표준 스케일링\n",
        "    scaler = StandardScaler()\n",
        "    df_scaled = scaler.fit_transform(df_drop)\n",
        "    df_scaled = pd.DataFrame(df_scaled, columns=df_drop.columns)\n",
        "\n",
        "    # 전처리된 데이터를 원래 데이터프레임에 업데이트\n",
        "    df.update(df_scaled)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdZNsXI9sea9",
        "outputId": "3e029fa6-3e53-45ba-a196-c27e68c19bfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train length: 7008\n",
            "y_train length: 7008\n",
            "x_valid length: 1752\n",
            "y_valid length: 1752\n"
          ]
        }
      ],
      "source": [
        "# 데이터 분할\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    train_df.drop([\"target\", \"ID\"], axis = 1),\n",
        "    train_df[\"target\"].astype(int),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=train_df[\"target\"].astype(int)\n",
        ")\n",
        "\n",
        "print(\"x_train length:\", len(x_train))\n",
        "print(\"y_train length:\", len(y_train))\n",
        "print(\"x_valid length:\", len(x_valid))\n",
        "print(\"y_valid length:\", len(y_valid))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjIsarjSzNlN"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzHohl6_zNlN",
        "outputId": "b5084734-45d8-4cc7-b66f-17b69b297235"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc: 0.464041095890411, auroc: 0.6407336297995615\n"
          ]
        }
      ],
      "source": [
        "# lgb dataset\n",
        "train_data = lgb.Dataset(x_train, label=y_train)\n",
        "valid_data = lgb.Dataset(x_valid, label=y_valid, reference=train_data)\n",
        "\n",
        "# lgb params\n",
        "params = {\n",
        "    \"boosting_type\": \"gbdt\",\n",
        "    \"objective\": \"multiclass\", # 다중 클래스 분류 수행할 때 사용하는 목적 함수\n",
        "    \"metric\": \"multi_logloss\", # 로그 손실(성능 평가 지표)\n",
        "    \"num_class\": 4,\n",
        "    \"num_leaves\": 50,  # 결정트리 최대 리프 수(복잡도 증가)\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"n_estimators\": 30,\n",
        "    \"random_state\": 42,\n",
        "    \"verbose\": 0,\n",
        "}\n",
        "\n",
        "# lgb train\n",
        "lgb_model = lgb.train(\n",
        "    params=params,\n",
        "    train_set=train_data,\n",
        "    valid_sets=valid_data,\n",
        ")\n",
        "\n",
        "# lgb predict\n",
        "y_valid_pred = lgb_model.predict(x_valid)\n",
        "y_valid_pred_class = np.argmax(y_valid_pred, axis = 1)\n",
        "\n",
        "# score check\n",
        "accuracy = accuracy_score(y_valid, y_valid_pred_class)\n",
        "auroc = roc_auc_score(y_valid, y_valid_pred, multi_class=\"ovr\")\n",
        "\n",
        "print(f\"acc: {accuracy}, auroc: {auroc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndGh9dVrzNlN",
        "outputId": "a29a9cda-fcb0-4b98-e2e0-1fdccb79f824"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        }
      ],
      "source": [
        "# performance 체크후 전체 학습 데이터로 다시 재학습\n",
        "lgb_model = lgb.train(\n",
        "    params=params,\n",
        "    train_set=train_data,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxkhz3BLzNlN"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynIYg2Fiv0go",
        "outputId": "d150c341-d764-4c9d-d486-5135de8d4e89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.03345759, 0.35758091, 0.56550803, 0.04345347],\n",
              "       [0.09095249, 0.28688127, 0.56554945, 0.05661679],\n",
              "       [0.19330374, 0.3229138 , 0.34461212, 0.13917034],\n",
              "       ...,\n",
              "       [0.05811356, 0.56967077, 0.26904339, 0.10317228],\n",
              "       [0.067821  , 0.31912057, 0.44577179, 0.16728664],\n",
              "       [0.03076975, 0.40286064, 0.517877  , 0.04849261]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_valid_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RwEG4Agwv2LE"
      },
      "outputs": [],
      "source": [
        "# lgb predict\n",
        "y_test_pred = lgb_model.predict(test_df.drop([\"target\", \"ID\"], axis = 1))\n",
        "y_test_pred_class = np.argmax(y_test_pred, axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EasPHtJyzNlN"
      },
      "source": [
        "### Output File Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Nug0CLZuzNlN"
      },
      "outputs": [],
      "source": [
        "# output file 할당후 save\n",
        "submission_df = submission_df.assign(target = y_test_pred_class)\n",
        "submission_df.to_csv(\"output.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Q9ia9FYd31Z8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
